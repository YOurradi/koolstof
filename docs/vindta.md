# **VINDTA DIC processing**

**koolstof** only deals with dissolved inorganic carbon.  For total alkalinity, use [Calkulate](https://calkulate.readthedocs.io/).

Like Calkulate, **koolstof** works by adding extra methods and attributes to a standard [pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html), which contains a `.dbs` file generated by a VINDTA.  The corresponding VINDTA-generated `logfile.bak` is also required.

All the code examples assume the import convention:

```python
import koolstof as ks
```

## **Import VINDTA files**

### **The `logfile.bak`: `read_logfile()`**

Import a `logfile.bak` into a standard pandas DataFrame with one row per DIC sample.

```python
logfile = ks.read_logfile("path/to/logfile.bak", methods="3C standard")
```

!!! example "`read_logfile`: optional keyword arguments"

    * `methods`: list of VINDTA method filenames used to run samples, excluding the `.mth` extensions

### **The `.dbs` file: `read_dbs()`**

Import a `.dbs` file into an enhanced DataFrame, rename its columns into a friendlier format, and link it to the already imported `logfile` DataFrame.

```python
dbs = ks.read_dbs("path/to/file.dbs", keep_all_cols=False, logfile=None)
```

!!! example "`read_dbs`: optional keyword arguments"

    * `keep_all_cols`: retain all columns from the `.dbs` (`True`) or just the most important ones (`False`)?
    * `logfile`: the DataFrame generated by importing the `logfile.bak` with `read_logfile()`.

## **Add sample metadata**

Once you've imported the files above, you need to add the following metadata as extra columns in the `dbs` enhanced DataFrame under the following column labels:

  * `salinity`: practical salinity (assumed 35 if not provided)
  * `temperature_dic_analysis`: temperature of DIC analysis in °C (assumed 25 °C if not provided)
  * `dic_certified`: certified DIC values for reference materials in μmol/kg-sw.  Non-reference samples should be set to `np.nan`.

You can also add the following logical columns to refine which samples and reference materials are used for processing and calibration:

  * `blank_good`: use this sample in assessing the coulometer blank value?
  * `k_dic_good`: use this reference material for calibration?

## **Calibrate DIC measurements**

Once you have imported the `logfile.bak`, `.dbs` file and added metadata, the `dbs` enhanced DataFrame has a series of methods available to calibrate the DIC results.

These must be run in a specific order, but each one also checks whether the necessary step before it has been run, and runs it automatically if not.  Therefore you only actually need to call the final method `dbs.calibrate_dic()`, unless for some reason you need to intervene during the processing.

!!! warning "Previous steps are only carried out if necessary"

    The later processing steps only re-run the earlier steps if they are required.  Mostly this is determined by checking for the presence or absence of a specific column in the `dbs` DataFrame, as described below.

!!! example "All processing steps in order"

    The full sequence of steps, plus their keyword arguments, is:

    1. [`dbs.get_logfile_index()`](#dbsget_logfile_index)
    2. [`dbs.get_sample_blanks(use_from=6)`](#dbsget_sample_blanks)
    3. [`dbs.get_session_blanks(batch_col="dic_cell_id")`](#dbsget_session_blanks)
    4. [`dbs.get_blank_corrections()`](#dbsget_blank_corrections)
    5. [`dbs.get_density()`](#dbsget_density)
    6. [`dbs.get_standard_calibrations()`](#dbsget_standard_calibrations)
    7. [`dbs.get_session_calibrations(batch_col="dic_cell_id")`](#dbsget_session_calibrations)
    8. [`dbs.calibrate_dic()`](#dbscalibrate_dic)

    See below for details of each step.

!!! tip "Keyword arguments are passed along"

    If using one of the later functions, you can pass any keyword arguments needed by the earlier functions to it as well, and they will get passed along until they are needed.

    For example, if you do `dbs.calibrate_dic(use_from=5)`, then the `use_from=5` gets passed along to the `dbs.get_sample_blanks()` step.

### **`dbs.get_logfile_index()`**

```python
dbs.get_logfile_index()
```

**Finds** the row in the `logfile` corresponding to each row of the `dbs` based on matching both the sample name in `dbs["bottle"]` and the analysis date and time.

**Adds a column** to `dbs`:

  * `logfile_index`: the index for the row in 

### **`dbs.get_sample_blanks()`**

```python
dbs.get_sample_blanks(use_from=6)
```

**Checks** for a `logfile_index` column in `dbs`, and runs `dbs.get_logfile_index()` if absent.

**Estimates** the coulometer blank for each sample as the average of the count increments, starting at the number of minutes set by `use_from`.

**Adds a column** to `dbs`:

  * `blank_here`: the coulometer blank for each sample in counts per minute.

### **`dbs.get_session_blanks()`**

```python
dbs.get_session_blanks(batch_col="dic_cell_id")
```

**Checks** for a `blank_here` column in `dbs`, and runs `dbs.get_sample_blanks()` if absent.

**Fits** the coulometer blanks for each sample as a function of time of analysis for each analysis session (as identified by the column `dbs[batch_col]`).

**Adds an attribute** to `dbs`:

  * `sessions`: a standard pandas DataFrame containing one row of metadata per analysis session.

## **Visualise the calibrations**

### **`dbs.plot_blanks()`**

### **`dbs.plot_k_dic()`**

### **`dbs.plot_dic_offset()`**
